import argparse
import os
import sys
import shutil
from concurrent.futures import ProcessPoolExecutor, wait
import time

import numpy as np
from scipy.spatial import KDTree

import CGNS.MAP as cgm
import pycgns_wrapper
from pycgns_wrapper import X, Y, Z

import parallel



def multiple_to_minimum(temp_folder: str, radius: float, i_task: int, n_task: int) -> tuple[str, int, int]:
    global multiple_points
    global multiple_kdtree

    n_global = len(multiple_points)
    first, last = parallel.get_range(i_task, n_task, n_global)
    n_local = last - first

    i_multiple_to_i_minimum = np.zeros((n_local,), dtype='int') - 1

    for i_global in range(first, last):
        i_local = i_global - first
        point_i = multiple_points[i_global]
        neighbors = multiple_kdtree.query_ball_point(point_i, radius)
        i_minimum = np.min(neighbors)
        assert 0 <= i_minimum < n_global
        i_multiple_to_i_minimum[i_local] = i_minimum

    output = f'{temp_folder}/i_multiple_to_i_minimum_{i_task}.npy'
    np.save(output, i_multiple_to_i_minimum)
    return output, first, last


def multiple_to_unique(zone: list, zone_size: np.ndarray, args: argparse.Namespace) -> np.ndarray:
    start = time.time()
    global multiple_points
    multiple_points, _, _, _ = pycgns_wrapper.readPoints(zone, zone_size)
    assert zone_size[0][0] == len(multiple_points)
    assert multiple_points.shape[1] == 3
    end = time.time()
    print(f'readPoints() costs {(end - start):.2f} seconds')

    n_multiple = len(multiple_points)

    start = time.time()
    global multiple_kdtree
    multiple_kdtree = KDTree(multiple_points)
    end = time.time()
    print(f'KDTree(multiple_points) costs {(end - start):.2f} seconds')

    temp_folder = f'{pycgns_wrapper.folder(args.input)}/temp{np.random.randint(0, 2**32)}'
    os.makedirs(temp_folder, exist_ok=True)

    executor = ProcessPoolExecutor(args.n_worker)
    n_task = args.n_task
    start = time.time()
    futures = []
    for i_task in range(n_task):
        futures.append(executor.submit(
            multiple_to_minimum, temp_folder, args.radius, i_task, n_task))
    done, not_done = wait(futures)
    assert len(done) == n_task
    assert len(not_done) == 0
    end = time.time()
    print(f'parallel multiple_to_minimum() costs {(end - start):.2f} seconds')

    # build a dict and array in the main process
    start = time.time()
    global i_multiple_to_i_unique
    i_multiple_to_i_unique = np.zeros((n_multiple,), dtype='int') - 1
    i_minimum_to_i_unique = dict()
    i_unique = 0
    for future in futures:
        npy, first, last = future.result()
        i_multiple_to_i_minimum = np.load(npy)
        n_local = len(i_multiple_to_i_minimum)
        assert n_local == last - first, (npy, n_local, first, last)
        for i_local in range(n_local):
            i_minimum = i_multiple_to_i_minimum[i_local]
            if i_minimum not in i_minimum_to_i_unique:
                i_minimum_to_i_unique[i_minimum] = i_unique
                i_unique += 1
            i_global = i_local + first
            i_multiple_to_i_unique[i_global] = i_minimum_to_i_unique[i_minimum]
    n_unique = len(i_minimum_to_i_unique)
    assert i_unique == n_unique
    assert (0 <= i_multiple_to_i_unique).all()
    assert (i_multiple_to_i_unique < n_unique).all()
    end = time.time()
    print(f'building i_multiple_to_i_unique costs {(end - start):.2f} seconds')
    print(f'i_unique = {n_unique}, i_multiple = {n_multiple}')

    # clean up temp files generated by each task
    shutil.rmtree(temp_folder)
    executor.shutdown()

    start = time.time()
    unique_points = np.ndarray((n_unique, 3), dtype=multiple_points.dtype)
    for i_minimum, i_unique in i_minimum_to_i_unique.items():
        unique_points[i_unique] = multiple_points[i_minimum]
    end = time.time()
    print(f'building unique_points costs {(end - start):.2f} seconds')

    start = time.time()
    n_check = min(n_multiple, args.n_check)
    for i_multiple in range(0, n_multiple, n_multiple // n_check):
        i_unique = i_multiple_to_i_unique[i_multiple]
        assert np.linalg.norm(multiple_points[i_multiple] - unique_points[i_unique]) < args.radius
    end = time.time()
    print(f'checking unique_points costs {(end - start):.2f} seconds')

    start = time.time()
    output_folder = pycgns_wrapper.folder(args.input)
    np.save(f'{output_folder}/i_multiple_to_i_unique.npy', i_multiple_to_i_unique)
    np.save(f'{output_folder}/unique_points.npy', unique_points)
    end = time.time()
    print(f'saving unique_points costs {(end - start):.2f} seconds')

    return unique_points


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        prog = f'python3 {sys.argv[0]}',
        description = 'Merge geometrically duplicated points in a single unstructured `Zone_t`.')
    parser.add_argument('--input', type=str, help='the CGNS file to be merged')
    parser.add_argument('--radius', type=float, default=1e-8, help='radius of the ball within which two points are treated as duplicated')
    parser.add_argument('--n_worker',  type=int, default=1, help='number of workers for running futures')
    parser.add_argument('--n_task',  type=int, default=1, help='number of tasks for running futures, usually >> n_worker')
    parser.add_argument('--n_check',  type=int, default=1000000, help='number of points for checking')
    parser.add_argument('--verbose', default=False, action='store_true')
    args = parser.parse_args()

    if args.verbose:
        print(args)

    # get the unique Zone_t
    start = time.time()
    cgns, zone, zone_size = pycgns_wrapper.getUniqueZone(args.input)
    pycgns_wrapper.removeSolutionsByLocation(zone, 'Vertex')
    end = time.time()
    print(f'cgm.load() costs {(end - start):.2f} seconds')

    global i_multiple_to_i_unique
    unique_points = multiple_to_unique(zone, zone_size, args)
    n_unique = len(unique_points)

    # update zone_size and GridCoordinates_t
    start = time.time()
    zone_size[0][0] = n_unique
    coords = pycgns_wrapper.getChildrenByType(
        pycgns_wrapper.getUniqueChildByType(zone, 'GridCoordinates_t'), 'DataArray_t')
    if args.verbose:
        print('\ncoords before merging:\n', coords)
    coords[X][1] = np.array(unique_points[:, X])
    coords[Y][1] = np.array(unique_points[:, Y])
    coords[Z][1] = np.array(unique_points[:, Z])
    if args.verbose:
        print('\ncoords after merging:\n', coords)
    end = time.time()
    print(f'update coordinates costs {(end - start):.2f} seconds')

    # update Elements_t's
    start = time.time()
    sections = pycgns_wrapper.getChildrenByType(zone, 'Elements_t')
    for section in sections:
        connectivity = pycgns_wrapper.getNodeData(
            pycgns_wrapper.getUniqueChildByName(section, 'ElementConnectivity'))
        n = len(connectivity)
        for i in range(n):
            connectivity[i] = i_multiple_to_i_unique[connectivity[i] - 1] + 1
        assert (1 <= connectivity).all() and (connectivity <= n_unique).all()
    end = time.time()
    print(f'updating connectivity costs {(end - start):.2f} seconds')

    # write the new mesh out
    start = time.time()
    output = f'{pycgns_wrapper.folder(args.input)}/merged.cgns'
    print('writing to', output)
    cgm.save(output, cgns)
    end = time.time()
    print(f'cgm.save() costs {(end - start):.2f} seconds')
